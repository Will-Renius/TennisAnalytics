---
title: "Random Forest"
author: "Will Renius"
date: "November 16, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries
```{r}
#detach("package:stats")
library(tidyverse)
library(lubridate)
```


```{r}
load("data/clean.men.data.RData")
men.data <- data.filtered
```

```{r}
str(men.data)
```


```{r}
men.data %>% group_by(upset) %>% summarize(count = n())

```


```{r}
train.data <- men.data %>% dplyr::filter(date.new < as.Date("2017-01-01")) %>% select(-date.new)
test.data <- men.data %>% dplyr::filter(date.new > as.Date("2017-01-01")) %>% select(-date.new)
#, date.new < as.Date("2018-01-01")
```


```{r}
require(randomForest)
imputed.data <- men.data %>% 
  mutate(
    avgW=replace(avgW, !is.finite(avgW), 1), 
    avgL=replace(avgL, !is.finite(avgL), 1)
    
    )
str(imputed.data)
win.odds.columns <- c("B365W", "B.WW" , "CBW" , "EXW" , "LBW" , "GBW" , "IWW" , "PSW" , "SBW" , "SJW" , "UBW" )
lose.odds.columns <- c("B365L", "B.WL" , "CBL" , "EXL" , "LBL" , "GBL" , "IWL" , "PSL" , "SBL" , "SJL" , "UBL" ) 


for(col.name in win.odds.columns){
  imputed.data[[col.name]][is.na(imputed.data[[col.name]])] <- imputed.data[["avgW"]][is.na(imputed.data[[col.name]])]
}
for(col.name in lose.odds.columns){
  imputed.data[[col.name]][is.na(imputed.data[[col.name]])] <- imputed.data[["avgL"]][is.na(imputed.data[[col.name]])]
}
str(imputed.data)

```
```{r}
summary((imputed.data$WPts + imputed.data$LPts)/2)
imputed.data <- imputed.data %>% 
  mutate(
    WPts=replace(WPts, !is.finite(WPts), 926), 
    LPts=replace(LPts, !is.finite(LPts), 926),
    
    maxLoseOdds=replace(maxLoseOdds, !is.finite(maxLoseOdds), -1), 
    maxWinOdds=replace(maxWinOdds, !is.finite(maxWinOdds), -1),
    minLoseOdds=replace(minLoseOdds, !is.finite(minLoseOdds), -1), 
    minWinOdds=replace(minWinOdds, !is.finite(minWinOdds), -1),
    maxProfit=replace(maxProfit, !is.finite(maxProfit), -1)

    )
str(imputed.data)
imputed.data <- imputed.data %>% mutate(upset = avgW > avgL )
```
```{r}
train.imputed <- imputed.data %>% dplyr::filter(date.new < as.Date("2017-01-01")) %>% select(-date.new)
test.imputed <- imputed.data %>% dplyr::filter(date.new > as.Date("2017-01-01")) %>% select(-date.new)
```
```{r}
# forest <- randomForest( x = select(train.imputed, -upset) , y = train.imputed$upset, xtest = select(test.imputed,-upset), ytest = test.imputed$upset)
# plot(forest)
```
```{r}
new.train <- imputed.data %>% dplyr::filter(date.new < as.Date("2017-01-01"), date.new >= as.Date("2015-01-01")) %>% select(-date.new)
# new.train <- sample_frac(train.imputed, .1, replace = F)
iris_rf = randomForest(upset~., data=new.train, ntree=200, proximity=T)
table(predict(iris_rf), new.train$upset)

```
```{r}
print("")
```

```{r}
testData <- test.imputed
iris_rf
plot(iris_rf)
importance(iris_rf)
irisPred = predict(iris_rf, newdata=testData)
table(irisPred, testData$upset)
plot(margin(iris_rf, testData$upset))
test.pred <- testData
test.pred$prediction <- irisPred
str(test.pred)
head(test.pred, 1)
```

```{r}
test.pred <- test.pred %>% mutate(upset.new =  avgW > avgL, upset.really.new = avgW -1 > avgL, upset.shawn = maxWinOdds > 2)
test.pred <- test.pred %>% mutate( winnings = case_when(upset == prediction & countWinOdds > 0 & countLoseOdds > 0 ~ maxProfit * 1, upset != prediction & countWinOdds > 0 & countLoseOdds > 0 ~ -1 * 1, TRUE ~ NA_real_))

sum(test.pred$winnings, na.rm = T)

test.pred %>% group_by(upset.new, upset, upset.really.new, upset.shawn) %>% summarise(sum(winnings, na.rm = TRUE), count =  sum(!is.na(winnings)), avg = mean(maxWinOdds), aaavg = mean(avgW))
# correct.pred <- test.pred %>% dplyr::filter(upset == prediction, countWinOdds > 0) %>% select(maxProfit)
# profit <- sum(correct.pred)
# incorrect.pred <- test.pred %>% dplyr::filter(upset != prediction, countWinOdds > 0) %>% select(maxProfit)
# incorrect.pred
# loss <- nrow(incorrect.pred)
# 
# print(profit)
# print(loss)
# print(profit - loss)
```
```{r}
naive <- test.pred %>% mutate( winnings = case_when(upset == F & countWinOdds > 0 & countLoseOdds > 0 ~ maxProfit * 1, upset != F & countWinOdds > 0 & countLoseOdds > 0 ~ -1 * 1, TRUE ~ NA_real_))
sum(naive$winnings, na.rm = T)
naive %>% group_by(upset, prediction) %>% summarise(sum(winnings, na.rm = TRUE))


```


```{r}
CM = table(irisPred, testData$upset)
accuracy = (sum(diag(CM)))/sum(CM)
print(CM)
print(accuracy)
```




Now We have ability to predict the winner with hi

```{r}
# ```{r}
# print(forest)
# ```
# ```{r}
# newPred = predict(forest, newdata=test.imputed)
# table(newPred, test.imputed$upset)
# ```
# ```{r}
# plot(margin(forest, test.imputed$upset))
# 
# ```
# ```{r}
# CM = table(irisPred, testData$Species)
# accuracy = (sum(diag(CM)))/sum(CM)
# print
# ```
# 
# 
# 
# ```{r}
# importance(forest)
# ```
# 
# ```{r}
# #test.imputed <-  rfImpute(x = test.data, y = test.data$upset)
# # t1 <- test.data
# # t1[is.na(t1)] <- NaN
# # head(t1, 1)
# # test.imputed <-  rfImpute(upset ~ .,t1 %>% select(upset, avgW, avgL))
# # train.imputed <- rfImpute(upset ~ .,train.data)
# 
# # Boston.rf=randomForest( x = select(train.imputed, -upset) , y = train.imputed$upset, xtest = select(test.imputed,-upset), ytest = test.imputed$upset)
# # plot(Boston.rf)
# ```
# ```{r}
# 
# ```
# 
# ```{r}
# #rfImpute
# ```
# 
# ```{r}
# 
# ```
# 
# 
# 
# 
# ```{r}
# save(men.data, file = "men.data.RData")
# 
# ```
```


